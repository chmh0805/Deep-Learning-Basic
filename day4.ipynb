{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist CNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto, InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, :, tf.newaxis] # x_train = np.expand_dims(x_train, -1)\n",
    "x_test = x_test[:, :, :, tf.newaxis]\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mnist = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mnist.add(keras.layers.Conv2D(32, padding='same', kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "conv_mnist.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "conv_mnist.add(keras.layers.Conv2D(64, padding='same', kernel_size=(3,3), activation='relu'))\n",
    "conv_mnist.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "conv_mnist.add(keras.layers.Conv2D(128, padding='same', kernel_size=(5,5), activation='relu'))\n",
    "conv_mnist.add(keras.layers.Flatten())\n",
    "conv_mnist.add(keras.layers.Dense(100, activation='relu'))\n",
    "conv_mnist.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               627300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 852,054\n",
      "Trainable params: 852,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mnist.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3154 - accuracy: 0.9034\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0599 - accuracy: 0.9814\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0405 - accuracy: 0.9877\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0298 - accuracy: 0.9910\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0230 - accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0173 - accuracy: 0.9947\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0085 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20acba8da48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_mnist.fit(x_train, y_train, batch_size=500, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.round(conv_mnist.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_predict.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = y_predict.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   62,   92,  247,  321,  359,  445,  448,  449,  582,  619,\n",
       "        659,  674, 1014, 1039, 1112, 1182, 1226, 1232, 1242, 1319, 1414,\n",
       "       1709, 1717, 1790, 1901, 2035, 2070, 2118, 2130, 2293, 2369, 2380,\n",
       "       2414, 2597, 2654, 2742, 2896, 2939, 2953, 2959, 2995, 3225, 3422,\n",
       "       3520, 3558, 3762, 3808, 3850, 3941, 3985, 4078, 4176, 4256, 4369,\n",
       "       4443, 4497, 4504, 4536, 4571, 4740, 4761, 4823, 5937, 5997, 6173,\n",
       "       6571, 6572, 6576, 6597, 6625, 6783, 8094, 8408, 9530, 9664, 9692,\n",
       "       9729], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = np.where(y_predict != y_test)[0]\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = np.random.choice(miss)\n",
    "plt.imshow(x_test[num])\n",
    "plt.title(\"True : {}, Predict : {}\".format(y_test[num], y_predict[num]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Mnist CNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = {\n",
    "    0 : 'T-shirt/top',\n",
    "    1 : 'Trouser',\n",
    "    2 : 'Pullover',\n",
    "    3 : 'Dress',\n",
    "    4 : 'Coat',\n",
    "    5 : 'Sandel',\n",
    "    6 : 'Shirt',\n",
    "    7 : 'Sneaker',\n",
    "    8 : 'Bag',\n",
    "    9 : 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = np.expand_dims(x_train, -1), np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.add(keras.layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "fashion_model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "fashion_model.add(keras.layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "fashion_model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "fashion_model.add(keras.layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "fashion_model.add(keras.layers.Flatten())\n",
    "fashion_model.add(keras.layers.Dense(100, activation='relu'))\n",
    "fashion_model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               320100    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 413,782\n",
      "Trainable params: 413,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.6984 - accuracy: 0.7536\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3894 - accuracy: 0.8609\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3313 - accuracy: 0.8809\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2989 - accuracy: 0.8936\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2676 - accuracy: 0.9039\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2548 - accuracy: 0.9077\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2365 - accuracy: 0.9136\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2249 - accuracy: 0.9183\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2120 - accuracy: 0.9224\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1996 - accuracy: 0.9280\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1857 - accuracy: 0.9322\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1750 - accuracy: 0.9364\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1689 - accuracy: 0.9373\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1593 - accuracy: 0.9417\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1471 - accuracy: 0.9463\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1413 - accuracy: 0.9482\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1320 - accuracy: 0.9513\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1237 - accuracy: 0.9549\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1158 - accuracy: 0.9584\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1062 - accuracy: 0.9623\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1008 - accuracy: 0.9626\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0982 - accuracy: 0.9632\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0864 - accuracy: 0.9688\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0783 - accuracy: 0.9715\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0726 - accuracy: 0.9739\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0678 - accuracy: 0.9758\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0650 - accuracy: 0.9769\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0537 - accuracy: 0.9814\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0497 - accuracy: 0.9829\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0471 - accuracy: 0.9833\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0415 - accuracy: 0.9857\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0398 - accuracy: 0.9861\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0318 - accuracy: 0.9890\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0387 - accuracy: 0.9858\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0268 - accuracy: 0.9910\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0300 - accuracy: 0.9891\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0225 - accuracy: 0.9924\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0228 - accuracy: 0.9918\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0255 - accuracy: 0.9909\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0196 - accuracy: 0.9934\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0116 - accuracy: 0.9965\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0219 - accuracy: 0.9919\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0227 - accuracy: 0.9916\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0176 - accuracy: 0.9939\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0182 - accuracy: 0.9933\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0179 - accuracy: 0.9938\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0139 - accuracy: 0.9955\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0170 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ad659db08>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_model.fit(x_train, y_train, batch_size=500, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = fashion_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = y_predict.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  12,   23,   25,   42,   49,   66,   68,   89,   98,  103,  117,\n",
       "        135,  141,  147,  150,  193,  239,  244,  247,  266,  271,  283,\n",
       "        316,  325,  352,  368,  374,  378,  381,  382,  389,  395,  413,\n",
       "        441,  452,  455,  457,  460,  474,  476,  478,  491,  495,  510,\n",
       "        529,  541,  548,  600,  602,  607,  623,  634,  635,  639,  669,\n",
       "        670,  688,  711,  713,  732,  753,  760,  787,  793,  830,  851,\n",
       "        881,  887,  905,  909,  921,  930,  937,  939,  960,  965,  972,\n",
       "        976,  977,  979,  984,  994,  997, 1000, 1005, 1025, 1055, 1056,\n",
       "       1104, 1111, 1129, 1130, 1131, 1139, 1142, 1152, 1165, 1197, 1231,\n",
       "       1254, 1261, 1280, 1287, 1300, 1305, 1329, 1336, 1376, 1387, 1388,\n",
       "       1399, 1408, 1425, 1449, 1462, 1469, 1482, 1501, 1509, 1515, 1522,\n",
       "       1527, 1533, 1557, 1572, 1602, 1620, 1626, 1629, 1632, 1640, 1642,\n",
       "       1645, 1650, 1665, 1679, 1712, 1736, 1739, 1743, 1754, 1771, 1778,\n",
       "       1810, 1822, 1833, 1846, 1917, 1922, 1942, 1943, 1953, 1954, 1968,\n",
       "       1980, 2001, 2006, 2037, 2067, 2111, 2162, 2190, 2191, 2195, 2196,\n",
       "       2236, 2245, 2272, 2278, 2280, 2311, 2312, 2318, 2337, 2352, 2357,\n",
       "       2359, 2381, 2382, 2396, 2425, 2431, 2435, 2451, 2455, 2457, 2469,\n",
       "       2478, 2479, 2485, 2487, 2506, 2507, 2527, 2540, 2548, 2551, 2571,\n",
       "       2580, 2588, 2589, 2593, 2599, 2615, 2628, 2629, 2653, 2670, 2681,\n",
       "       2684, 2695, 2698, 2717, 2721, 2776, 2779, 2806, 2817, 2832, 2839,\n",
       "       2840, 2842, 2843, 2856, 2860, 2865, 2869, 2884, 2898, 2900, 2903,\n",
       "       2909, 2914, 2918, 2919, 2920, 2942, 2951, 2953, 2960, 2965, 2979,\n",
       "       2985, 2997, 3004, 3008, 3019, 3038, 3058, 3084, 3116, 3123, 3132,\n",
       "       3167, 3181, 3188, 3209, 3229, 3232, 3240, 3241, 3252, 3258, 3262,\n",
       "       3282, 3284, 3297, 3310, 3322, 3323, 3327, 3334, 3342, 3349, 3356,\n",
       "       3370, 3393, 3416, 3436, 3441, 3457, 3466, 3468, 3476, 3488, 3489,\n",
       "       3496, 3499, 3531, 3532, 3535, 3540, 3553, 3554, 3568, 3585, 3606,\n",
       "       3609, 3613, 3625, 3643, 3657, 3658, 3669, 3671, 3673, 3674, 3706,\n",
       "       3730, 3731, 3733, 3741, 3753, 3787, 3799, 3800, 3804, 3809, 3811,\n",
       "       3816, 3829, 3830, 3842, 3861, 3864, 3871, 3876, 3880, 3884, 3896,\n",
       "       3918, 3938, 3939, 3940, 3953, 3955, 3974, 3984, 3987, 3999, 4005,\n",
       "       4019, 4041, 4049, 4056, 4067, 4079, 4082, 4092, 4093, 4101, 4106,\n",
       "       4109, 4111, 4132, 4138, 4142, 4143, 4148, 4153, 4166, 4192, 4193,\n",
       "       4194, 4213, 4231, 4233, 4250, 4251, 4272, 4280, 4299, 4307, 4404,\n",
       "       4411, 4416, 4433, 4446, 4460, 4500, 4501, 4505, 4526, 4542, 4559,\n",
       "       4568, 4569, 4599, 4618, 4668, 4672, 4685, 4686, 4693, 4694, 4724,\n",
       "       4727, 4738, 4744, 4746, 4758, 4764, 4784, 4803, 4810, 4817, 4828,\n",
       "       4846, 4850, 4880, 4882, 4886, 4920, 4922, 4934, 4956, 4995, 5006,\n",
       "       5009, 5032, 5037, 5052, 5077, 5101, 5172, 5178, 5186, 5197, 5204,\n",
       "       5210, 5248, 5249, 5255, 5259, 5260, 5266, 5272, 5297, 5316, 5334,\n",
       "       5336, 5338, 5345, 5375, 5381, 5397, 5410, 5424, 5438, 5441, 5468,\n",
       "       5470, 5471, 5474, 5476, 5497, 5510, 5511, 5512, 5520, 5522, 5533,\n",
       "       5562, 5566, 5568, 5569, 5575, 5576, 5592, 5594, 5597, 5601, 5623,\n",
       "       5648, 5655, 5695, 5701, 5713, 5721, 5734, 5760, 5795, 5806, 5885,\n",
       "       5907, 5918, 5938, 5939, 5946, 5966, 5971, 5974, 5981, 5987, 5990,\n",
       "       6002, 6006, 6008, 6023, 6024, 6061, 6065, 6096, 6103, 6127, 6132,\n",
       "       6159, 6160, 6162, 6169, 6175, 6201, 6207, 6223, 6248, 6254, 6258,\n",
       "       6293, 6296, 6300, 6314, 6331, 6335, 6344, 6356, 6365, 6377, 6395,\n",
       "       6402, 6404, 6405, 6433, 6437, 6441, 6444, 6452, 6464, 6472, 6485,\n",
       "       6500, 6513, 6514, 6517, 6531, 6542, 6558, 6565, 6566, 6575, 6584,\n",
       "       6593, 6625, 6640, 6654, 6676, 6679, 6689, 6701, 6710, 6716, 6730,\n",
       "       6733, 6751, 6801, 6809, 6826, 6832, 6844, 6846, 6855, 6859, 6861,\n",
       "       6866, 6869, 6874, 6899, 6908, 6926, 6928, 6957, 6958, 6961, 6984,\n",
       "       6990, 6996, 6997, 7004, 7026, 7033, 7049, 7068, 7078, 7103, 7105,\n",
       "       7111, 7125, 7130, 7138, 7167, 7177, 7188, 7189, 7190, 7195, 7221,\n",
       "       7222, 7228, 7243, 7249, 7258, 7262, 7265, 7369, 7393, 7416, 7424,\n",
       "       7442, 7464, 7497, 7526, 7555, 7571, 7596, 7646, 7654, 7714, 7755,\n",
       "       7761, 7778, 7800, 7801, 7803, 7809, 7812, 7818, 7847, 7864, 7868,\n",
       "       7890, 7899, 7905, 7906, 7924, 7948, 7976, 7977, 7986, 7992, 7998,\n",
       "       8005, 8007, 8014, 8031, 8061, 8069, 8070, 8079, 8121, 8156, 8202,\n",
       "       8205, 8227, 8237, 8259, 8292, 8296, 8324, 8348, 8353, 8377, 8382,\n",
       "       8399, 8429, 8454, 8463, 8465, 8470, 8525, 8532, 8538, 8557, 8569,\n",
       "       8580, 8591, 8598, 8607, 8610, 8617, 8618, 8621, 8633, 8634, 8640,\n",
       "       8645, 8658, 8664, 8669, 8688, 8693, 8695, 8705, 8706, 8714, 8717,\n",
       "       8725, 8728, 8745, 8757, 8763, 8764, 8768, 8772, 8804, 8818, 8832,\n",
       "       8834, 8879, 8884, 8914, 8919, 8933, 8939, 8946, 8952, 8958, 8972,\n",
       "       9017, 9032, 9059, 9061, 9062, 9094, 9095, 9112, 9133, 9140, 9146,\n",
       "       9149, 9165, 9179, 9197, 9204, 9210, 9227, 9235, 9237, 9238, 9251,\n",
       "       9260, 9272, 9291, 9307, 9308, 9334, 9349, 9398, 9402, 9405, 9445,\n",
       "       9531, 9571, 9573, 9574, 9590, 9601, 9632, 9662, 9666, 9679, 9687,\n",
       "       9690, 9692, 9729, 9748, 9835, 9856, 9880, 9884, 9891, 9904, 9928,\n",
       "       9945, 9946, 9947, 9955, 9961, 9972, 9977, 9991], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = np.where(y_predict != y_test)[0]\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "miss_num = np.random.choice(miss)\n",
    "plt.imshow(x_test[miss_num])\n",
    "plt.title(\"True : {}, Predict : {}\".format(y_dict[y_test[miss_num]], y_dict[y_predict[miss_num]]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
