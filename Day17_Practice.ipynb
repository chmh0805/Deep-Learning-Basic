{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 손글씨 숫자 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 MNIST 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST\n",
    " - 손글씨 숫자 이미지 집합\n",
    " - 실험용 데이터로 많이 사용\n",
    " - 0~9까지의 숫자 이미지로 구성(훈련 60,000장, 시험 10,000장)\n",
    " - 28 x 28 크기의 회색조 이미지(1채널)로, 각 픽셀은 0에서 255까지의 값을 취한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모듈\n",
    "- sys 모듈을 이용해 부모디렉터리의 파일을 가져올 수 있도록 설정\n",
    "(sys.path.append(os.pardir))\n",
    "- dataset 디렉토리에 있는 mnist.py의 load_mnist 함수를 import 한다.\n",
    "    - 첫번째는 인터넷에서 다운로드하며 이후부터는 pickle 파일에 의해 로컬에 저장된 파일을 읽어온다.\n",
    "- **normalize** : 입력 이미지의 픽셀값을 0.0 ~ 1.0 사이의 값으로 정규화 여부를 정함.\n",
    "(정규화하면 overflow를 방지할 수 있고, 학습 속도를 향상시킬 수 있다.)\n",
    "- **flatten** : 입력 이미지를 평탄값 즉, 1차원 배열로 생성 여부를 정함.\n",
    "- **fromarray** : 넘파이로 저장된 이미지 데이터를 PIL용 데이터 객체로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)\n",
    "\n",
    "print(img.shape)\n",
    "img = img.reshape(28, 28)\n",
    "print(img.shape)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지를 1차원 넘파이 배열로 저장했기 때문에 이미지를 다시 표시하기 위해선 28x28 크기의 배열로 다시 변형해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 신경망의 추론 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력층 뉴런 784개(28x28), 출력층 뉴런 10개(0~9까지)로 구성\n",
    "- 은닉층은 총 두 개\n",
    "- 첫번째 은닉층은 50개의 뉴런\n",
    "- init_network()에서는 pickle 파일인 sample_weight.pkl에 저장된 *학습된 가중치, 매개변수*를 읽는다. 가중치와 편향 매개변수가 딕셔너리 변수로 저장되어 있다.\n",
    "- 이미 학습된 매개변수를 이용하기 때문에 test_set만 불러와서 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True)\n",
    "    # normalize=True 시 overflow 방지 + 학습 속도 향상 (크기가 작아지기 때문.)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"./ch03/sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c) # 오버플로 방지\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    \n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    \n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**평가**   \n",
    "   \n",
    "신경망에 의한 추론을 수행해보고, **정확도**(분류가 얼마나 올바른가)를 평가해보자.   \n",
    "   \n",
    "- 가장 먼저 mnist 데이터 셋을 얻고 네트워크를 생성\n",
    "- for문을 돌려 x에 저장된 이미지 데이터를 1장씩 꺼내 predict()함수로 분류\n",
    "- predict() 함수는 각 레이블의 확률을 넘파이 배열로 반환\n",
    "- 예를 들어 [0.1, 0.3, ...] 이라 하면 이미지가 숫자 0일 확률은 10%라고 해석\n",
    "- 그런 다음 np.argmax() 함수를 이용해 배열에서 값이 가장 큰 원소의 인덱스를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n",
      "\n",
      "Error index:\n",
      "[8, 33, 66, 92, 124, 149, 217, 233, 241, 245, 247, 259, 290, 300, 313, 320, 321, 340, 341, 352, 358, 362, 381, 445, 448, 449, 478, 479, 495, 502, 507, 511, 531, 543, 551, 565, 569, 578, 582, 591, 610, 619, 627, 629, 659, 684, 691, 707, 717, 720, 740, 791, 810, 839, 844, 857, 881, 882, 898, 924, 938, 939, 947, 950, 956, 965, 982, 999, 1014, 1032, 1039, 1044, 1050, 1062, 1068, 1082, 1107, 1112, 1114, 1119, 1124, 1181, 1191, 1192, 1194, 1198, 1204, 1206, 1224, 1226, 1232, 1242, 1247, 1251, 1256, 1260, 1283, 1289, 1299, 1319, 1325, 1326, 1328, 1337, 1364, 1378, 1393, 1410, 1413, 1429, 1433, 1440, 1444, 1465, 1466, 1467, 1494, 1500, 1522, 1525, 1527, 1530, 1549, 1553, 1559, 1569, 1581, 1601, 1609, 1621, 1634, 1640, 1671, 1678, 1681, 1696, 1709, 1717, 1722, 1732, 1737, 1751, 1754, 1759, 1765, 1772, 1773, 1782, 1790, 1800, 1813, 1828, 1850, 1857, 1865, 1878, 1880, 1901, 1913, 1917, 1930, 1938, 1952, 1955, 1956, 1970, 1973, 1981, 1984, 2016, 2024, 2035, 2040, 2043, 2044, 2053, 2068, 2070, 2098, 2109, 2115, 2118, 2129, 2130, 2135, 2138, 2148, 2182, 2185, 2186, 2189, 2266, 2272, 2293, 2299, 2325, 2369, 2371, 2378, 2380, 2387, 2393, 2395, 2404, 2406, 2422, 2425, 2433, 2462, 2473, 2488, 2514, 2526, 2542, 2545, 2556, 2559, 2560, 2573, 2574, 2598, 2607, 2610, 2648, 2654, 2670, 2695, 2713, 2751, 2760, 2770, 2771, 2780, 2832, 2836, 2850, 2863, 2896, 2906, 2907, 2921, 2925, 2927, 2945, 2953, 2970, 2995, 3005, 3060, 3073, 3102, 3110, 3114, 3117, 3130, 3136, 3145, 3160, 3167, 3189, 3193, 3206, 3240, 3254, 3269, 3288, 3316, 3329, 3330, 3405, 3422, 3437, 3447, 3450, 3460, 3475, 3490, 3503, 3520, 3549, 3550, 3558, 3559, 3567, 3573, 3597, 3604, 3629, 3662, 3674, 3681, 3687, 3716, 3718, 3726, 3727, 3732, 3751, 3757, 3767, 3776, 3778, 3780, 3796, 3801, 3806, 3808, 3811, 3817, 3818, 3821, 3833, 3834, 3836, 3838, 3846, 3848, 3850, 3853, 3855, 3862, 3869, 3893, 3902, 3906, 3926, 3941, 3943, 3946, 3951, 3962, 3976, 3985, 4000, 4017, 4063, 4065, 4072, 4075, 4078, 4093, 4131, 4140, 4152, 4154, 4163, 4176, 4177, 4199, 4201, 4211, 4212, 4224, 4238, 4248, 4256, 4271, 4289, 4297, 4300, 4306, 4313, 4315, 4317, 4330, 4344, 4355, 4356, 4369, 4374, 4400, 4405, 4423, 4433, 4435, 4449, 4451, 4477, 4497, 4498, 4521, 4523, 4540, 4571, 4575, 4578, 4601, 4615, 4639, 4731, 4735, 4740, 4751, 4761, 4785, 4807, 4808, 4814, 4823, 4837, 4860, 4874, 4876, 4879, 4880, 4886, 4890, 4910, 4915, 4950, 4956, 4966, 4990, 5046, 5054, 5065, 5067, 5068, 5078, 5086, 5140, 5165, 5183, 5210, 5246, 5331, 5457, 5495, 5600, 5601, 5611, 5617, 5620, 5623, 5634, 5642, 5714, 5734, 5749, 5821, 5835, 5842, 5862, 5887, 5888, 5891, 5913, 5922, 5926, 5936, 5937, 5955, 5972, 5973, 5985, 5992, 6035, 6042, 6043, 6059, 6065, 6071, 6081, 6091, 6112, 6157, 6166, 6168, 6172, 6173, 6324, 6347, 6390, 6391, 6421, 6425, 6426, 6505, 6555, 6558, 6560, 6568, 6571, 6574, 6597, 6598, 6603, 6625, 6632, 6641, 6642, 6645, 6651, 6706, 6721, 6740, 6744, 6746, 6755, 6765, 6769, 6775, 6783, 6785, 6796, 6817, 6847, 6906, 6926, 7121, 7130, 7198, 7216, 7220, 7233, 7338, 7426, 7432, 7434, 7451, 7459, 7492, 7498, 7511, 7539, 7545, 7797, 7800, 7812, 7821, 7839, 7842, 7847, 7849, 7850, 7851, 7856, 7858, 7859, 7870, 7886, 7888, 7899, 7905, 7917, 7918, 7921, 7928, 7945, 7990, 8020, 8062, 8072, 8081, 8091, 8094, 8095, 8183, 8196, 8272, 8277, 8279, 8294, 8316, 8332, 8339, 8406, 8408, 8410, 8493, 8520, 8522, 8553, 8863, 9007, 9009, 9010, 9013, 9015, 9019, 9024, 9036, 9045, 9071, 9182, 9209, 9280, 9316, 9422, 9427, 9433, 9446, 9456, 9465, 9482, 9538, 9544, 9587, 9595, 9614, 9624, 9634, 9642, 9643, 9662, 9664, 9679, 9692, 9698, 9700, 9712, 9716, 9719, 9726, 9729, 9732, 9738, 9741, 9744, 9745, 9749, 9751, 9752, 9768, 9770, 9777, 9779, 9792, 9808, 9811, 9839, 9856, 9858, 9867, 9879, 9888, 9890, 9892, 9893, 9905, 9925, 9940, 9941, 9943, 9944, 9970, 9982, 9986]\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data() # ((x_train, t_train), (x_test, t_test))\n",
    "network = init_network() # 가중치 W, 바이어스 b\n",
    "\n",
    "error_index = []\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "    if p != t[i]:\n",
    "        error_index.append(i)\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)) + \"\\n\")\n",
    "print(\"Error index:\\n\" + str(error_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__정규화__*   \n",
    "데이터를 특정 범위로 변환하는 처리. 예를 들어 0 - 255 범위인 각 픽셀의 값을 0.0 - 1.0의 범위로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__전처리__*   \n",
    "신경망의 입력 데이터에 특정 변환을 가하는 것. 입력 이미지 데이터에 대한 전처리 작업으로 정규화를 수행한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 배치 처리\n",
    "**Weight와 bias 값을 최대 효율로 학습**시키기 위해 사용한다.   \n",
    "batch size : 1 step에서 사용하는 데이터 수   \n",
    "step : Weight, bias를 1회 업데이트 하는 것   \n",
    "epoch : 전체 데이터를 1바퀴 돌며 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 신경망 각 층의 배열 형상의 추이\\n X     W1      W2      W3      ->    Y   \\n784  784x50  50x100  100x10         10 \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 신경망 각 층의 배열 형상의 추이\n",
    " X     W1      W2      W3      ->    Y   \n",
    "784  784x50  50x100  100x10         10 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 배치 처리를 위한 배열들의 형상 추이\\n   X       W1      W2      W3      ->     Y\\n100x784  784x50  50x100  100x10        100x10\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 배치 처리를 위한 배열들의 형상 추이\n",
    "   X       W1      W2      W3      ->     Y\n",
    "100x784  784x50  50x100  100x10        100x10\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**배치 처리 구현**   \n",
    "- 이미지를 100장씩 끊어서 처리한다.\n",
    "- 이전의 방식은 한 장씩 끊어서 처리하였음.\n",
    "- range() 함수가 반환하는 리스트를 바탕으로 x[i:i+batch_size]에서 데이터를 묶는다.\n",
    "- x[0:100], x[100:200], ... 와 같이 앞에서부터 100장씩 묶는다.\n",
    "- argmax() 최댓값의 인덱스를 가져온다.최댓값의 인덱스의 기준을 명시하기 위해 axis=1 변수를 지정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__argmax__*   \n",
    "axis의 값은 기준값을 의미한다. 0일 때는 row 방향으로, 1일 때는 column 방향으로, 2일 때는 z축을 기준으로 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1], [0.9, 0.9, 0.9]])\n",
    "np.argmax(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정리\n",
    "    - 각 층의 뉴런들이 다음 층의 뉴런으로 신호를 전달하는 점에서 앞 장의 퍼셉트론과 같다.\n",
    "    - 다음 뉴런으로 갈 때 신호를 변화시키는 활성화 함수에 큰 차이가 존재한다.\n",
    "    - 신경망에서는 매끄럽게 변화하는 시그모이드 함수를 활성화 함수로 사용한다.\n",
    "    - 퍼셉트론에서는 갑자기 변화하는 계단 함수를 활성화 함수로 사용한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
